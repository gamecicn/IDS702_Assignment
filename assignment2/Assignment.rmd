---
title: "Assignment 2"
author: "Maobin Guo"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
    
---

```{r setup, echo = FALSE, include=FALSE}

options(warn=-1)
options(xtable.comment = FALSE)


library(ggplot2)
library(xtable)
library(rms)


```


# Question1 

```{r echo = FALSE}

rm(list = ls())

df <- read.csv("OldFaithful.csv", stringsAsFactors = FALSE, sep = "," ,dec="," )
df$Duration <- as.double(df$Duration)
df$DurationCent <- df$Duration - mean(df$Duration)
```

##### 1.1 Fit a regression model for predicting the interval between eruptions from the duration of the previous one, to the data, and interpret your results.



```{r echo = FALSE}

model <- lm(Interval~DurationCent, data=df)

```
\hfill\break

**Model Result:**


```{r echo = FALSE, results='asis'}

xtable(model)

#par(mfrow=c(2,2))
#plot(model, which = 1, col=c("blue4"))
#plot(model, which = 2, col=c("blue4"))
#plot(model, which = 3, col=c("blue4"))
#plot(model, which = 5, col=c("blue4"))

```

**Interpret:**
According to the observing data, the average interval between eruptions is 71 minutes. Every minute change of erupting duration before the gap will change the interval in the same direction by 10.7 minutes. 


##### 1.2 Include the 95% confidence interval for the slope, and explain what the interval reveals about the relationship between duration and waiting time.

\hfill\break

**95% Confidence Interval:**

```{r echo = FALSE, results='asis'}

xtable(confint(model))

```

\hfill\break

**Interpret:**

The 95% confidence interval for DurationCent (Centered duration) to predict the interval between two eruptions is (9.49, 11.98) minutes. Because 0 does not appear in the interval, there is enough evidence to say a relationship between duration and interval. 


##### 1.3 Describe in a few sentences whether or not you think the regression assumptions are plausible based on residual plots (do not include any plots).

\hfill\break

**Description:**

From the residual plot, there is no evidence that the regression assumptions were broke. 
- There is no apparent trend in the residual scatter plot. 
- The distribution of residuals is interdependent in the observations.
- The distribution of residuals is very like a normal distribution. 

\hfill\break

##### 1.4 Fit another regression model for predicting interval from duration and day. Treat day as a categorical/factor variable. Is there a significant difference in mean intervals for any of the days (compared to the first day)? Interpret the effects of controlling for the days (do so only for the days with significant effects, if any).

```{r echo = FALSE, results='asis'}
df$Date <- as.factor(df$Date)

model_withday <- lm(Interval~DurationCent+Date, data=df)

```
\hfill\break

There is no significant difference in mean intervals for any of the days. Because:

- p-value of each day is > 0.05 
- The confidence interval of each day's slope contains 0. 

Days is an invalid factor to predict intervals with duration.


##### 1.5 Perform an F-test to compare this model to the previous model excluding day. In context of the question, what can you conclude from the results of the F-test?

\hfill\break
**Result:**
```{r echo = FALSE, results='asis'}

ftest_result <- anova(model, model_withday)

xtable(ftest_result)
```
 
\hfill\break
**Interpret:**

According to the F-test, the p-value is 0.98, which means we cannot refuse the hypothesis that the two models are equal to predict interval. We can also conclude that there is no interaction between days and duration. 


##### 1.6 Using k-fold cross validation (with k=10), compare the average RMSE for this model and the average RMSE for the previous model excluding day. Which model appears to have higher predictive accuracy based on the average RMSE values?
 
```{r echo = FALSE, results='asis'}

set.seed(123) # use whatever number you want

new_df <- df[sample(nrow(df)),]
# Define the number of folds you want
K <- 10
# Define a matrix to save your results into
RSME <- matrix(0,nrow=K,ncol=1)
# Split the row indexes into k equal parts
kth_fold <- cut(seq(1,nrow(df)),breaks=K,labels=FALSE)
# Now write the for loop for the k-fold cross validation


for(k in 1:K){
  # Split your data into the training and test datasets
  test_index <- which(kth_fold==k)
  train <- df[-test_index,]
  test <- df[test_index,]
  
  y_test_pred <- predict(model_withday, test)
  testMSE <- mean((df$Interval- y_test_pred)^2);
  # Now that you've split the data, 
  RSME[k,] <- sqrt(testMSE)
}

RSME_withday = mean(RSME)


for(k in 1:K){
  # Split your data into the training and test datasets
  test_index <- which(kth_fold==k)
  train <- df[-test_index,]
  test <- df[test_index,]
  
  y_test_pred <- predict(model, test)
  testMSE <- mean((df$Interval- y_test_pred)^2);
  # Now that you've split the data, 
  RSME[k,] <- sqrt(testMSE)
}

RSME_normal = mean(RSME)
#RSME_withday
```
\hfill\break
**Interpret:**

Model without days has higher predictive accuracy based on the average RMSE.   

\newpage


#         MATERNAL SMOKING AND BIRTH WEIGHTS

 
```{r echo = FALSE}

rm(list = ls())

df <- read.csv("smoking.csv", stringsAsFactors = FALSE, sep = "," ,dec="," )

#Remove gestation
df = subset(df, select = -c(date, gestation))

# collapse race categories from 0 - 5 into one category for race = white
df[df$mrace < 6, ]$mrace = 5
df[df$med <= 7 & df$med >= 6, ]$med = 7


# Factorize 
df$med   <- as.factor(df$med)
df$mrace <- as.factor(df$mrace)
df$smoke <- as.factor(df$smoke)

df$parityCent <- df$parity - mean(df$parity)
df$mageCent <- df$mage - mean(df$mage)
df$mhtCent <- df$mht - mean(df$mht)
df$mpregwtCent <- df$mpregwt - mean(df$mpregwt)


```



```{r echo = FALSE, include=FALSE}

hist(df$bwt.oz)
# Conclude:  df$bwt.oz is normal distribution 


df$parity_sqrt <- sqrt(df$parity)
df$inc_sqrt <- sqrt(df$inc)
 

hist(df$mht)
hist(df$mpregwt)
hist(df$inc)

```

```{r echo = FALSE, include=FALSE}

# Plot 
plot(y = df$bwt.oz, x = df$parity) 
plot(y = df$bwt.oz, x = df$mht) 
plot(y = df$bwt.oz, x = df$mpregwt) 
plot(y = df$bwt.oz, x = df$inc) 

# Terriable no linear relation ship

```  


```{r echo = FALSE, include=FALSE}
boxplot(bwt.oz~smoke,  data=df)
boxplot(bwt.oz~med,  data=df)
boxplot(bwt.oz~mrace,  data=df)

```



```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=parity, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ med) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=parity, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ mrace) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=parity, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ smoke) 

```


```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=mage, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ med) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=mht, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ med) 

```


```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=mpregwt, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ med) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=inc, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ med) 

```


```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=inc, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ mrace) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=parity, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ mrace) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=mht, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ mrace) 

```

```{r echo = FALSE, include=FALSE}

ggplot(df,aes(x=mpregwt, y=bwt.oz)) +
  geom_point(alpha = .5,colour="blue4") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ mrace) 

```



```{r echo = FALSE, include=FALSE}

# 
#raw_model_1 <- lm(bwt.oz ~ parity + mrace + mage_log + med + mht + mpregwt + inc + smoke, data=df)
#
#raw_model_1 <- lm(bwt.oz ~ parity + mrace + mage_log + mht + mpregwt + inc + smoke, data=df)
#
#
#raw_model_2 <- lm(bwt.oz ~ parity + mrace*mht + mage_log + mpregwt  + smoke, data=df)
#
#raw_model_3 <- lm(bwt.oz ~ parity + smoke  + mage_log + mpregwt  + mht, data=df)

```

```{r echo = FALSE, include=FALSE}

#model_null <- lm(bwt.oz~1,data=df)
#raw_full <- lm(bwt.oz ~ parity_sqrt + mrace + mage + med + mht + mpregwt + inc_sqrt + smoke, data=df)
#
#Model_forward_aic <- step(model_null, scope = formula(raw_full),direction="forward",trace=0)
#
#Model_forward_bic <- step(model_null, scope = formula(raw_full),direction="forward",trace=0, k = #log(n))
#
#
#Model_back_aic <- step(raw_full, direction="backward",trace=0)
#
#Model_back_bic <- step(raw_full, direction="backward",trace=0, k = log(n))
#
#Model_both_aic <- step(model_null, scope = formula(raw_full),direction="both",trace=0)
#
#Model_both_bic <- step(model_null, scope = formula(raw_full),direction="both",trace=0, k = #log(n))

#_model = lm(formula = bwt.oz ~ smoke + mht + mrace + mpregwt + parity, data = df)

_model = lm(formula = bwt.oz ~ smoke + mht + mrace + mpregwt + parity_sqrt, data = df)


# TO Answer :2
#What is a likely range for the difference in birth weights for smokers and non-smokers?
# confint(_model) 

# TO Answer :3
#
#Is there any evidence that the association between smoking and birth weight differs by mother’s #race? If so, characterize those differences.

ggplot(df,aes(x=smoke, y=bwt.oz, fill=smoke)) +
  geom_boxplot()  +
  scale_fill_brewer(palette="Blues") +
  theme_classic() + theme(legend.position="none") +
  facet_wrap( ~ mrace)

```

\hfill\break

## Summary

A linear regression model was built to query the relationship between maternal smoking and the baby's birth weight IN this investigation and some related questions. The model indicates a strong relationship between maternal smoking with a baby's birth weight. By controlling other factors, the mother's smoke would decrease the baby's birth weight.

\hfill\break

## Introduction

This analysis based on a dataset from a study carried between 1960 and 1967 at the Kaiser Foundation Hospital in Oakland, CA. `r nrow(df)` observations were included in the analysis. Linear regression was exploited as the primary technique to quest the answer to the following questions. 

- Is there any relationship between brith weight and mother's smoking? If any, to what extend brith weight was affected by the behavior. A quantifiable  relationships is expected in the conlusion of this study. 

- If the relationship exists, is it behaved in the same manner under any circumstance? Since the dataset also includes the mother's age, race, educational background, income, and other factors, it is natural to think about whether the relationship behaves the same in different situations.

- Apart from the mother's smoking, is there any other factors in the data that would affect birth weight. 

\hfill\break

## Data

\hfill\break

### Overview

The dataset includes `r nrow(df)` observations. Since it was already cleaned, there is not missing data in it. Here are important columns that would be included in the analysis:

| Col Name      | Status     | Meaning     |
| :-------------: | :----------: | :-----------: |
| bwt.oz | Perfectly normal distribution   |  Birth weight in ounces. Its distribution is.  |
| parity | Like exponential distribution, uneven |  Total number of previous pregnancies, including fetal deaths and still births. |
| mrace | Category variable , uneven  | Mother’s race or ethnicity |
| mage |  Nearly normal  | Mother’s age in years at termination of pregnancy |
| med |  Uneven  | Mother’s education |
| mht |  Nearly normal  | 	Mother’s height in inches |
| mpregwt |  Nearly normal  | 	Mother’s pre-pregnancy weight in pounds |
| inc |  Like exponential distribution  | 	Family yearly income in 2500 increments|
| smoke |  Nearly even  | 	Does mother smoke?|


**Summary:**

- The response variable is in good shape.
- Parity and inc should be transformed.
- Parity inc, and med have some segments which have only a few observations.  

\hfill\break

### Relationship between the response variable and each predictor

\hfill\break

```{r echo = FALSE, out.width=c('25%', '25%', '25%', '25%'), fig.show='hold'}

plot(y = df$bwt.oz, x = sqrt(df$parity), main = "Fig. 1") 
plot(y = df$bwt.oz, x = df$mage, main = "Fig. 2") 
plot(y = df$bwt.oz, x = df$mht, main = "Fig. 3") 
plot(y = df$bwt.oz, x = df$mpregwt, main = "Fig. 4") 
plot(y = df$bwt.oz, x = sqrt(df$inc), main = "Fig. 5") 
boxplot(bwt.oz~smoke,  data=df, main = "Fig. 6")
boxplot(bwt.oz~med,  data=df, main = "Fig. 7")
boxplot(bwt.oz~mrace,  data=df, main = "Fig. 8")

```

**Summary:**

- Minor relationships can be found in figure 1 and figure4. 
- In figure 6, box1's response value is higher than box2's, which indicates that maybe there is a significant difference in birth weight between the two groups.


### Relationship between Smoke and Birth Weight under other factors

\hfill\break

```{r echo = FALSE, out.width=c('25%', '25%', '25%', '25%'), fig.show='hold', message=FALSE}



ggplot(df,aes(x=parity, y=bwt.oz)) +
  geom_point(alpha = .5,colour="grey") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ smoke) 

ggplot(df,aes(x=mage, y=bwt.oz)) +
  geom_point(alpha = .5,colour="grey") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ smoke) 

ggplot(df,aes(x=mht, y=bwt.oz)) +
  geom_point(alpha = .5,colour="grey") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ smoke) 

ggplot(df,aes(x=mpregwt, y=bwt.oz)) +
  geom_point(alpha = .5,colour="grey") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ smoke) 

ggplot(df,aes(x=inc, y=bwt.oz)) +
  geom_point(alpha = .5,colour="grey") +
  geom_smooth(method="lm",col="red3") + theme_classic() +
  facet_wrap( ~ smoke) 


ggplot(df,aes(x=smoke, y=bwt.oz, fill=smoke)) +
  geom_boxplot()  +
  scale_fill_brewer(palette="Blues") +
  theme_classic() + theme(legend.position="none") +
  facet_wrap( ~ mrace)

ggplot(df,aes(x=smoke, y=bwt.oz, fill=smoke)) +
  geom_boxplot()  +
  scale_fill_brewer(palette="Blues") +
  theme_classic() + theme(legend.position="none") +
  facet_wrap( ~ med)

```

\hfill\break
**Summary:**

- The non-smoking group's Brith Weight is higher than the smoking group under each condition.  


## Model

\hfill\break

### Variable Transformation and Selection

##### Transformation

Since the response variable is in good shape of the normal distribution, there is no need to transform it. Predict variables: 'parity' and 'inc' should be transformed because their distribution is similar to the exponential distribution. Square was chosen to exert on 'parity' and 'inc' because they all contain 0 value, which would cause an error for the log operation. 

##### Variable Selection

According to the exploratory data analysis (EDA) plot, only some predict variables show an apparent relationship with the response variable. However, quantitive analysis is required before exclude them from the  model. A Multiple Linear Regression (MLR) model, including all factors, was built to explore each predictor variable's significance of influence on the response variable. Statistic methods such as p-value, ANOVA, and VIF were used on the preliminary model and models based on it to test whether a variable is important enough for staying at the model. R's auto-explore function 'step' with various metrics (AIC, BIC) and actions (forward, backward, stepwise) are also exploited to select variables. 
    

###  Model and Assessment 

The  modle is :

$$
  bwt.oz = \beta_{1}*smoke_{i} + \beta_{2}*mht_{i} + \beta_{3}*mrace_{i} + \beta_{4}*mpregwt_{i} + \beta_{5}*sqrt(parity)_{i} + \beta_{0} + \varepsilon_{i}
$$

```{r echo = FALSE, results='asis'}
xtable(_model)

fsta <- summary(_model)$fstatistic
model_pvalue <- pf(fsta[1],fsta[2],fsta[3],lower.tail=F)
attributes(model_pvalue) <- NULL

```

- R Square is : `r summary(_model)$r.squared`
- Model p-value is : `r model_pvalue`

**Cofidence Itervals (95%) for each slope:**

```{r echo = FALSE, results='asis'}
xtable(confint(_model))
```

#### Assessment

\hfill\break

```{r echo = FALSE, out.width=c('25%', '25%', '25%', '25%'), fig.show='hold'}

plot(_model, which = 1, col=c("blue4"))
plot(_model, which = 2, col=c("blue4"))
plot(_model, which = 3, col=c("blue4"))
plot(_model, which = 4, col=c("blue4"))

```

**Linearity**

- According to the residuals plot, residuals are normally distributed in this model.


**Correlation of Errors**

- There is no apparent trend in the errors. It is predictable since this dataset is no time-series data. 

**Constant variance of error**

- There is no perceivable pattern in the residuals along with the fitted value.

**Outliers & High-leverage**

- Outliers: Some outliers exist in the dataset. However, there are no potential gains of the model's performance after removing them. One potential reason is that the dataset is big enough to ignore a few outlier's influences.

- High Leverage: There are a few high leverage points. However, their cook distance indicates that they are not high influence points.  

**Multi-Collinearity**

- According to the VIF value of the model, no multi-collinearity 

### Summary

According to abvoe verification, the valitiy of the model can be confirmed. Moreover, several conclusion can be deduced from model:

- The smoking behavior can significantly decrease birth weight by 9.4 oz on average. 95% CI is : `r c(confint(_model)[2,1], confint(_model)[2,2]) `

- A model with interaction items between `smoke` and `mrace` was built to check whether smoking performs differently according to mothers' race. The result is that the mother's race will not affect the association between smoking and birth weight by the mother's race.

-  Apart from smoking, 'mht', 'parity', and 'mpregwt' also significantly influence birth weights in statistics but slightly in science. Some races (black, Asian) have evidence negative influence on birth weights while other rances have no such influence.  

\hfill\break

## Conclusion and Deficiency


**Conclusion**


From the analysis, a multi-linear regression model was built to identify the relationship between maternal smoking and birth weights. The negative relationship was confirmed quantitively by the model. Some other birth weight factors were found, but their influence is slight, especially compared with smoking. The race is a complex influence; some races tend to have lighter babies than others. 

**Deficiency**


1. The  model's R-Square value is only 0.155.

2. There are some outliers in the model. Even though some index indicates that these outliers are unimportant, further investigation is needed. 
















